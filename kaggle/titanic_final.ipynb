{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43155149934810955"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(15.1 + 15.3 + 2.7)/(15.1 +43.6 + 15.3 +2.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化，导包读数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "output_path = \"D:/temp_files/datasets/titanic/\"\n",
    "train_path = \"D:/temp_files/datasets/titanic/train.csv\"\n",
    "test_path = \"D:/temp_files/datasets/titanic/test.csv\"\n",
    "train_data = pd.read_csv(train_path)\n",
    "test_data = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先把小于1的\n",
    "train_data.loc[train_data.Age < 1, 'Age'] = 1\n",
    "test_data.loc[test_data.Age < 1, 'Age'] = 1\n",
    "# 使用平均年龄来填充年龄中nan值\n",
    "train_data['Age'].fillna(train_data.Age.mean(), inplace=True)\n",
    "test_data['Age'].fillna(test_data.Age.mean(), inplace=True)\n",
    "test_data['Fare'].fillna(test_data.Fare.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 观察Embarked值的种类\n",
    "train_data.Embarked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Embarked'].fillna('S', inplace=True)\n",
    "test_data['Embarked'].fillna('S', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 特征选择\n",
    "\n",
    "    应该先检查在该领域中是否存在成熟的理论模型，若存在，则依据该理论模型来选取特征，否则，自行选取（在这个问题上）\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征选择\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "X = train_data[features]\n",
    "y = train_data['Survived']\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# train_X, validate_X,train_y, validate_y= train_test_split(X, y, random_state=222200801)\n",
    "test_X = test_data.loc[:, features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 特征提取和缩放\n",
    "\n",
    "    使用pd.get_dummies()来将特征独热编码， 使用minmaxscaler进行归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_need_dummied: list[str] = ['Embarked','Sex']\n",
    "features_need_scaled = ['Fare', 'Age']\n",
    "# 独热编码\n",
    "def implement_dummies(data: pd.DataFrame, features: list[str]) -> pd.DataFrame:\n",
    "    res = pd.DataFrame()\n",
    "    for feature in features:\n",
    "        dummy = pd.get_dummies(data[feature])\n",
    "        res = pd.concat([res, dummy], axis=1)\n",
    "    data = data.drop(labels=features, axis=1)\n",
    "    data = pd.concat([data, res], axis=1)\n",
    "    return data\n",
    "\n",
    "# 归一化\n",
    "def implement_minmax_scaler(data: pd.DataFrame, features: list[str]) -> pd.DataFrame:\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    res = pd.DataFrame()\n",
    "    for feature in features:\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled = scaler.fit_transform(pd.DataFrame(data.index + data[feature]))\n",
    "        scaled = pd.DataFrame(scaled, columns=[feature])\n",
    "        res = pd.concat([res, scaled], axis=1)\n",
    "    data = data.drop(labels=features, axis=1)\n",
    "    data = pd.concat([data, res], axis=1)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = implement_dummies(X, features_need_dummied)\n",
    "test_X = implement_dummies(test_X, features_need_dummied)\n",
    "X = implement_minmax_scaler(X, features_need_scaled)\n",
    "test_X = implement_minmax_scaler(test_X, features_need_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将X、test_X、y存入文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv(output_path + \"X\" + \".csv\",index=True)\n",
    "test_X.to_csv(output_path + \"test_X\" + \".csv\",index=True)\n",
    "y.to_csv(output_path + \"y\" + \".csv\",index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6cd7ecbf46b3498f952f614292bd9b98de37d868a382baadab1fa3f5188ed6c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
