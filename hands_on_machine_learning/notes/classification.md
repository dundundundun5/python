# classification
## lab

    cost function
    opt lab: gradient descent for LR
    overfitting
## 逻辑回归
虽然名叫“回归”，但实际上属于分类问题的算法，输出类别，类别是一种离散值

如果让线性回归预测事物分为某一类的概率，
那么线性回归也可以用作分类，只不过分类的结论是概率而不是类别
1. 符号
    
    sigmoid函数，这是一个由输入产生概率的函数
    $$g(z)=\frac{1}{1+e^{-z}} $$
    令
    $$z=f_{\vec w,b}(\vec x)=\vec w\vec x+b$$
    将线性回归的预测值作为sigmoid函数的输入，则得到了逻辑回归的表达式:
    $$f_{\vec w,b}(\vec x)=\frac{1}{1+e^{-(\vec w\vec x+b)}}=\frac{1}{1+e^{(-\vec w\vec x+b_1)}}\quad b_1=-b\\
    $$
    由于常数的数值和字母无关，所以把b1替换回b:
    $$
    f_{\vec w,b}(\vec x)=\frac{1}{1+e^{(-\vec w\vec x+b)}}$$
    有时也写作，当给定xwb时，输出为1的概率，即：
    $$f_{\vec w,b}(\vec x)=P(y=1|\vec x;\vec w,b) $$
2. 理想的代价函数？

    理想的代价函数就是和线性回归的代价函数保持一致：
    $$J(\vec w, b)=\frac{1}{m}\sum_{i=1}^{m}\frac{1}{2}(\hat{y}^{(i)}-y^{(i)})^2=\frac{1}{m}\sum_{i=1}^{m}\frac{1}{2}(f_{\vec{w},b}(\vec{x}^{(i)})-y^{(i)})^2

     $$(1)
     先说结论：
     
        若使用(1)，代价函数则会呈现为在定义域内具有多个极小值的波浪曲线，这不利于用梯度下降算法，对代价函数作最小化计算

     再说细节：
        
        原本分母的2m的2被拆分到求和内部，实际上2是为了梯度下降时对代价函数求导从而抵消系数，并没有数学意义
3. 实际的代价函数

    * 损失函数

        在给出实际代价函数之前，首先给出损失函数的定义
        $$L(f_{\vec w,b }(\vec{x}^{(i)}),y^{(i)})=\begin{cases}
        -\log(f_{\vec w,b }(\vec{x}^{(i)}))\quad y^{(i)}=1 \\
        -\log(1-f_{\vec w,b }(\vec{x}^{(i)}))\quad y^{(i)}=0
        \end{cases} $$
        根据曲线（笔记内不绘制）得：
            
            当实际为1时，预测越接近1，损失函数值就越收敛于0，预测越接近0，损失函数值越趋于无穷大
            
            当实际为0时，预测越接近0，损失函数值就越收敛于0，预测越接近1，损失函数值越趋于无穷大
    * 简化的损失函数

        分段函数不容易代入运算，故合并为：

        $$L(f_{\vec w,b }(\vec{x}^{(i)}),y^{(i)})=\\\overbrace{-y^{(i)}\log(f_{\vec w,b }(\vec{x}^{(i)}))-(1-y^{(i)})\log(1-f_{\vec w,b }(\vec{x}^{(i)}))} $$
        此处运用了数字电路中逻辑表达式合并的思路，将分段函数合并成功。
    * 真~代价函数   

        根据逻辑回归特点而重置的代价函数，其实是由上面定义损失函数合成的：

        $$J(\vec w, b)=\frac{1}{m}\sum_{i=1}^{m}L(f_{\vec w,b }(\vec{x}^{(i)}),y^{(i)})\\=-\frac{1}{m}\sum_{i=1}^{m}(y^{(i)}\log(f_{\vec w,b }(\vec{x}^{(i)}))+(1-y^{(i)})\log(1-f_{\vec w,b }(\vec{x}^{(i)}))) $$

            
## 逻辑回归与线性回归
1. 关系
## 决策边界
相当于门槛，预测结果相对于门槛的高低用于决定最终输出结果为0或1，决策边界并不总是简单的函数
## 过拟合的解决方案
1. 更多数据
2. 特征选择
3. 正则化
