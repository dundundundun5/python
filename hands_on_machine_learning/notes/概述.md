# 概述
用于梳理本书第一章的概述知识

## 机器学习
机器学习是关于如何让机器在不编码规则的情况下从数据中不断学习从而更好地处理特定任务
1. 机器学习的概念

        一个计算机程序利用经验E来学习任务T，性能是P，如果针对任务T的性能P随着经验E不断增长，则称为机器学习
2. 机器学习适用于

    
        有解决方案的问题。需要大量人工微调和遵循大量规则的问题可以靠机器学习简化代码

        传统方法难以解决的问题

        环境有波动的问题

        洞察复杂问题和大量数据
3. 机器学习应用于

        自动分类新闻NLP、通过脑部扫描发现肿瘤CNN、检测信用卡欺诈（异常检测）
        基于以前的购买记录推荐给客户可能感兴趣的产品（人工神经网络）、基于很多性能指标来预测公司下一年的收入（回归模型）
        用直观的图标表示复杂的高维数据集（数据可视化、降维）
---
## 机器学习的分类
1. 按人类是否监督

    * 有监督学习
    * 无监督学习
    * 半监督学习
    * 强化学习
2. 按是否可以动态增量学习

    * 在线学习
    * 批量学习
3. 按数据的匹配参照物

    * 基于实例的学习
    * 基于模型的学习
---
### 有监督学习
* 标签    

        提供给算法的包含所需解决方案的训练集称为标签
1. 分类

    通过大量实例及其所属的类别进行训练，学习对新实例的分类

        垃圾邮件过滤器
2. 回归

    通过给定一组称为预测器的特征来预测一个目标数值

        联合多种特征，预测汽车价格
3. 回归与分类

    一些回归算法也可以用于分类，反之亦然

        回归->"属于某个类别的概率"->分类
4. 有监督学习的重要算法

        k-近邻算法、线性回归、逻辑回归、支持向量机（SVM）、决策树和随机森林
        神经网络（某些神经网络架构可以是无监督的，比如自动编码器和受限玻尔兹曼机）
### 无监督学习
无监督学习的训练集都是么有标记的，系统会在没有监督引导的前提下自动学习
1. 聚类

    将人群分成几个不同的簇

        k-均值算法、DBSCAN、分层聚类分析（HCA）
2. 可视化算法

    利用降维（在不丢失太多信息的前提下简化数据）的技术，绘制可视化的数据表示
        
        主成分分析
        核主成分分析
        局部线性嵌入
        t-分布随机近邻嵌入
3. 异常检测

    检测看起来与训练集中的所有实例不同的新实例

        单类SVM
        孤立森林
4. 关联规则学习

    挖掘大量数据，发现属性之间的有趣联系

        Apriori
        Eclat
### 半监督学习
是有监督学习和无监督学习的结合
### 强化学习
学习系统能够观察环境、做出选择、执行动作、获得回报。自行学习最好的策略，从而随着时间的推移获得最大的回报

    例如机器人行走学习
---
### 批量学习
必须使用所有可用的数据进行训练
* 批量学习的迭代

        在新和旧组合数据集的基础上重新训练系统的新版本，用新系统取代旧系统
### 在线学习
在线学习并非要求实时，而是要求可以循序渐进地给系统提供数据（系统需要接受持续的数据流），系统相应地对数据流的变化做出快速、自主的反应

* 学习率
  
    在线学习系统适应不断变化数据的速度
---
### 基于实例的学习
系统学习示例，然后使用相似度度量比较新实例和已经学习的实例，从而泛化新实例
### 基于模型的学习
构建示例的模型，然后使用模型进行预测

---
### 机器学习项目的流程
1. 研究数据
2. 选择模型
3. 使用训练数据进行训练
4. 应用模型对新示例进行预测，检验模型的泛化程度
---
## 机器学习的困难
1. 数据不足，成千上万个示例才够
2. 数据不具有代表性

    * 采样偏差

        采样方式欠妥导致数据不具有道标
3. 低质量数据

    数据错误、数据缺失、异常多、噪声多，需要统一化
4. 特征工程

    只有训练数据里包含足够多的相关特征以及较少的无关特征，系统才能完成学习

    * 特征选择（从现有特征中选择最有用的特征）
    * 特征提取（整合现有特征，产生更有用的特征）
    * 通过收集新数据创建新特征  
5. 过拟合

    和幸存者偏差一样，模型只在训练集表现良好，泛化能力很差

    * 正则化
  
            通过约束模型（减少特征的个数）使其更简单，并降低过拟合的风险
    * 超参数

            是算法的参数，和算法本身无关，超参数必须在训练之前对算法设置好，并在训练期间保持不变
6. 欠拟合

    模型太过简单导致连在训练集的表现都不行
---
##  模型的评估
1. 单个模型的评估

    将数据分为训练集和测试机，从而得出泛化误差
2. 多个模型的评估

   
    * 验证集/开发集

        是训练集的一部分。在简化的训练集上训练具有各种超参数的多个模型
    
    * 保持验证

        用一块验证集评估几种候选模型并选择最佳模型
        
    * 交叉验证

        分割出多个小验证机重复进行交叉验证，评估出平均的泛化误差
     * 忌讳

        保持一个测试集和训练集，生成不同超参数训练出来的不同模型，用测试集评估这些模型的泛化误差。

        如果不停通过改变超参数来达成模型对测试集的准确预测。实际上会产生模型对测试机的过拟合（解决方法：保持验证）

        如果训练集和验证集的相对大小控制不当，训练出来的模型也会不准确（解决方法：交叉验证）
3. No Free Lunch

    如果对数据没有任何的假设，就没有理由更偏好某一个模型
    