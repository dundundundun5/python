# 机器学习

## 监督学习 supervised

    从标注数据中学习预测模型的机器学习问题，本质是输入到输出的映射的统计规律

    * 输入空间
    * 实例 通常由特征向量表示
    * 特征空间
    * 输出空间
    回归问题 - 输入输出均连续
    分类问题 - 输出离散
    标注问题 - 输入输出均为变量序列
1. 基本假设

    输入X输出Y具有联合分布概率P(X,Y)
2. 模型的形式

    条件概率分布P(Y|X)或者决策函数Y=F(X)
3. 假设空间的定义

    是所有可能模型的集合
4. 输入输出的形式

    输入是假定为n维的列向量，每一维代表一种输入，一个列向量决定一个输出
5. hat 

    表示预测，非实际
### 模型
### 策略
1. 损失函数

    度量模型一次预测好坏 L(Y, f(X))
2. 风险函数 

    度量平均意义下模型预测的好坏

    Rexp(f) = Ep[L(Y,f(X))] 
    
    就是联合分布中连续变量的期望，是二重积分
    见张宇概率P85 
    
    即模型的每一次度量好坏 x 当次度量出现的概率

    L(y,f(x))P(x,y)dxdy
3. 经验风险

    模型f(X)关于训练集的平均损失

    Remp(f) = sum(1->n){L(yi, f(xi))} / N
4. 切比雪夫大数定律

    经验风险会趋于风险函数
### 算法
用于求解最优模型
## 无监督学习 unsupervised
只有输入，没有输出

本质是学习数据中的潜在结构

训练集只包含输入

## 强化学习

# 模型的评估

## 训练误差与测试误差
1. 训练误差
   
    每个样本的损失函数的平均值
2. 测试误差

    每个样本都来自测试集，每个样本的损失函数的平均值
3. 误差率

    0-1损失函数，预测和真实值不相等则为1，相等则为0，所有集合内相加总和再取平均值
4. 准确率

    0-1损失函数，与上面相反，两者概率和 = 100%
## 过拟合

通过训练集学习所得的模型包含参数过多，导致已有数据训练效果好，但未知数据预测效果差

## 正则化
实现结构风险最小化策略
1. 正则化项

    L1范数、L2范数 ？
## 交叉验证
1. 简单交叉验证
2. s折交叉验证
3. 留一交叉验证
## 泛化能力
1. 泛化误差
   
   模型对未知数据预测的误差
   
2. 泛化误差上界

    泛化误差的概率上界

    当样本容量增加时，泛化上界趋于0

    假设空间容量越大，模型越难学
# 生成模型与判别模型
1. 生成模型

    由数据学习联合分布概率P(X,Y),然后求出P(Y|X)作为预测模型，即生成模型

    朴素贝叶斯法、隐马尔可夫模型

    输入和输出均为随机变量

2. 判别模型

    由数据直接学习决策函数f(X)或者条件概率分布P(Y|X),即判别模型

    k近邻法、感知机、决策树
    不需要输入和输出为随机变量
3. 比较

|生成模型|判别模型|
|-|-|
|数据量大|少|
|可还原联合分布概率|可直接面对预测，准确度更高|
|收敛速度更快|可简化学习问题|
|可反映同类数据本身的相似度|不可|
|隐变量存在时可用||

